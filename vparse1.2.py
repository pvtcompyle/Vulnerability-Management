# Ingest and parse vulnerability scan reports into a consolidated csv.
# This requires the scans to be exported to csv files and placed in the 
# same folder the script is ran from. 
#
# The file names are used to identify the ScanType (infrastructure, Public
# Zone, Workstations, etc.). The current naming convention is:
#   Dynamic_Scan_Type_Scan.csv (ie Dynamic_Workstations_Scan.csv)
# A regex search on the file names is used to extract the scantype
# Scandate is added which is the year and month prior to processing the csv.

import os
import glob
import datetime
import re
import pandas as pd

#++++++++++++++++++++++
#++ Define Functions ++
#++++++++++++++++++++++

def getcsvlist():
    # Get a list of all csv files in the current working directory
    # and store their names in files.
    global files
    global dir
    extension = 'csv'
    os.chdir(dir)
    files = glob.glob('*.{}'.format(extension))

def consolidatescans():
    global scantype
    for f in files:
        print('Processing: ', f)
        scantype = re.search('Dynamic_(.*?)_Scan', f).group(1)
        data = pd.read_csv(f, sep=',')
        if f==files[0]:
            data.insert(0, "ScanType", scantype, allow_duplicates=True)
            data.insert(1, "ScanDate", scandate, allow_duplicates=True)
            data.to_csv(logfile, sep=',', index=False)
        else:
            data.insert(0, "ScanType", scantype, allow_duplicates=True)
            data.insert(1, "ScanDate", scandate, allow_duplicates=True)        
            data.to_csv(logfile, mode='a', sep=',', header=False, index=False)
    print('Consolidation Complete')

def parsetrash():
    print('Parsing results to exclude CVSS scores below 7.0 ...')
    
    for f in files:
        print('Processing', f)
        data = pd.read_csv(f, sep=',')
        data = data[data['CVSS'] > 7.0]
        data = data.sort_values(['Host', 'CVSS'], ascending=[True, False])
        print(f)

        data.to_csv(f, sep=',', index=False)
    print('Trash results below 7.0 are parsed.')

def seperatehosts():
    global parsefile
    hosts_frame = pd.read_csv(parsefile)
    hosts = hosts_frame['Host'].unique()
    
    for h in hosts:
        result = hosts_frame[hosts_frame['Host'].str.match(h)]
        hostfile = 'results\\hosts\\' + h + '.csv'
        hostfile = os.path.join(dir, hostfile)
        print('Processing ', hostfile)
        result.to_csv(hostfile, sep=',', index=False)
    print('Hosts have been seperated into individual files.')
    
#++++++++++++++++++++
#++ Initialization ++
#++++++++++++++++++++

dir=os.getcwd()

# Get the date and break it into YYYY-MM -1 month
today=datetime.date.today()
month = int(today.strftime("%m"))-1
month = str(month).zfill(2)
scandate= ''.join([str(today.strftime("%Y-")),month])

files=[]
header=""
subdirectory = "results"
scantype=""

# Create results directory to store output files 
try:
    os.mkdir(subdirectory)
except Exception:
    pass
try:
    os.mkdir('results\\hosts')
except Exception:
    pass

logfile=os.path.join(subdirectory, 'vulnerability scans.csv')
parsefile=os.path.join(subdirectory, 'ActionableVulnerabilities.csv')

#+++++++++++++++++++++
#+++ Start Program +++
#+++++++++++++++++++++

getcsvlist()
parsetrash()
#consolidatescans()
#seperatehosts()

os.system('pause')
