from colorama import Style
import pandas as pd
import re
import os
import glob
import numpy as np

def getcsv():
    extension = 'csv'
    files = glob.glob('*.{}'.format(extension))
    return(files)
def consolidatescans(files, scandate, resultsdir, outfile):
    for f in files:
        print(Style.DIM + '\tProcessing: ', f)
        scantype = re.search('(.*?)_Scan', f).group(1)
        data = pd.read_csv(f, sep=',')
        if f==files[0]:
            data.insert(0, "ScanType", scantype, allow_duplicates=True)
            data.insert(1, "ScanDate", scandate, allow_duplicates=True)
            data.to_csv(outfile, sep=',', index=False)
        else:
            data.insert(0, "ScanType", scantype, allow_duplicates=True)
            data.insert(1, "ScanDate", scandate, allow_duplicates=True)        
            data.to_csv(outfile, mode='a', sep=',', header=False, index=False)
        parsetrash(outfile)
    print(Style.RESET_ALL)
    print('Consolidation Complete')

def getDataFrame(file):
    data_frame = pd.read_csv(file, sep=',')
    return(data_frame)
def parsetrash(pfile):
    print(Style.DIM + '\tParsing results to exclude Low and Informational vulnerabilities...')
    data = pd.read_csv(pfile, sep=',')
    data = data[data['CVSS'] > 3.9]
    data = data.sort_values(['Host', 'CVSS'], ascending=[True, False])
    data.to_csv(pfile, sep=',', index=False)
    print('\tTrash results below Medium are parsed.')
    print(Style.RESET_ALL)
def seperatehosts(file, dir):
    data_frame = pd.read_csv(file)
    hosts = data_frame['Host'].unique()
    hostcount = countinstance(file, 'Host')
    tick=0
    for h in hosts:
        tick += 1
        current = int((tick/hostcount)*100)
        current = str(current)+'%'
        result = data_frame[data_frame['Host'].str.match(h)]
        hostfile = 'results\\hosts\\' + h + '.csv'
        hostfile = os.path.join(dir, hostfile)
        print(Style.DIM + current, 'complete.', '     Processing ', hostfile)
        result.to_csv(hostfile, sep=',', index=False)
    print(Style.RESET_ALL)
    print('Hosts have been seperated into individual files.')
    return(hosts)
def countinstance(file, field):
    import pandas as pd
    data_frame = pd.read_csv(file)
    hosts = data_frame[field].unique()
    hostcount = len(hosts)
    return (hostcount)
def getlastmonth():
    import datetime
    today=datetime.date.today()
    month = int(today.strftime("%m"))-1
    month = str(month).zfill(2)
    scandate= ''.join([str(today.strftime("%Y-")),month])
    return(scandate)
def summary(data_frame,summaryfile):
    hostlist = data_frame['Host'].unique()
    hostSummary = []
    # Get Criticalities and calculate risk scores
    for h in hostlist:
        hostresult = data_frame[data_frame['Host'].str.match(h)]
        critresult = hostresult[hostresult['Risk'].str.match('Critical')]
        count_crit = critresult['Risk'].count()
        critresult = hostresult[hostresult['Risk'].str.match('High')]
        count_high = critresult['Risk'].count()
        critresult = hostresult[hostresult['Risk'].str.match('Medium')]
        count_med = critresult['Risk'].count()
        riskScore = ((count_crit*10)+(count_high*2)+count_med)/100
        hostSummary.append([h, count_crit, count_high, count_med,riskScore])
    # Write summary to file
    for h in hostSummary:
        pd.DataFrame(hostSummary).to_csv(summaryfile, sep=',', header=['Host','Critical','High','Medium','RiskScore'], index=False)
    hostSummary = getDataFrame(summaryfile)
    hostSummary = hostSummary.sort_values(by=['RiskScore'], ascending=False)
    for h in hostSummary:
        pd.DataFrame(hostSummary).to_csv(summaryfile, sep=',', index=False)
def showlist(array):
    for e in array:
        print(e)